# ğŸ“ AI Interview Coach - æ¨¡å‹è®­ç»ƒå®Œæ•´æ–¹æ¡ˆ

## ğŸ“ é¡¹ç›®æ–‡ä»¶ç»“æ„

```
gw/
â”œâ”€â”€ ai_interview_coach/          # ä¸»é¡¹ç›®ç›®å½•
â”‚   â”œâ”€â”€ models/                  # âœ… è®­ç»ƒæ¨¡å— (æ–°å¢)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ answer_scorer.py    # BERTè¯„åˆ†æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # æ•°æ®åŠ è½½å™¨
â”‚   â”‚   â”œâ”€â”€ train.py            # è®­ç»ƒè„šæœ¬
â”‚   â”‚   â””â”€â”€ evaluate.py         # è¯„ä¼°è„šæœ¬
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/                 # âœ… å·¥å…·è„šæœ¬ (æ–°å¢)
â”‚   â”‚   â”œâ”€â”€ generate_interview_data.py   # ç”Ÿæˆæ ‡æ³¨æ•°æ®
â”‚   â”‚   â”œâ”€â”€ annotation_helper.py         # äº¤äº’å¼æ ‡æ³¨å·¥å…·
â”‚   â”‚   â””â”€â”€ prepare_asap_data.sh         # ASAPæ•°æ®å‡†å¤‡
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                # æœåŠ¡å±‚
â”‚   â”‚   â”œâ”€â”€ eval.py             # (åŸæœ‰) å¯å‘å¼è¯„åˆ†
â”‚   â”‚   â””â”€â”€ model_eval.py       # âœ… (æ–°å¢) æ¨¡å‹è¯„åˆ†æœåŠ¡
â”‚   â”‚
â”‚   â”œâ”€â”€ data/training_data/      # è®­ç»ƒæ•°æ®ç›®å½•
â”‚   â”‚   â”œâ”€â”€ asap_essays.csv              # (å¾…ä¸‹è½½) ASAPæ•°æ®
â”‚   â”‚   â”œâ”€â”€ interview_answers_to_annotate.json   # (ç”Ÿæˆ) å¾…æ ‡æ³¨
â”‚   â”‚   â””â”€â”€ interview_answers_annotated.json     # (äººå·¥) å·²æ ‡æ³¨
â”‚   â”‚
â”‚   â”œâ”€â”€ checkpoints/             # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”‚   â”œâ”€â”€ stage1/              # Stage 1: ASAPé¢„è®­ç»ƒ
â”‚   â”‚   â”‚   â””â”€â”€ best_model.pt
â”‚   â”‚   â””â”€â”€ stage2/              # Stage 2: é¢è¯•å¾®è°ƒ
â”‚   â”‚       â””â”€â”€ best_model.pt
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation_results/      # è¯„ä¼°ç»“æœ
â”‚   â”‚   â”œâ”€â”€ evaluation_results.json
â”‚   â”‚   â””â”€â”€ evaluation_plots.png
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt         # âœ… (å·²æ›´æ–°) æ·»åŠ è®­ç»ƒä¾èµ–
â”‚   â”œâ”€â”€ TRAINING_README.md       # âœ… è¯¦ç»†è®­ç»ƒæ–‡æ¡£
â”‚   â””â”€â”€ (å…¶ä»–åŸæœ‰æ–‡ä»¶...)
â”‚
â”œâ”€â”€ QUICKSTART.md               # âœ… å¿«é€Ÿå¼€å§‹æŒ‡å—
â””â”€â”€ IMPLEMENTATION_SUMMARY.md   # âœ… å®æ–½æ€»ç»“
```

## ğŸ¯ ä½ éœ€è¦åšçš„äº‹æƒ…

### âš¡ ä»Šå¤©ç«‹å³æ‰§è¡Œ

#### 1. ä¸‹è½½ ASAP æ•°æ®é›† (10åˆ†é’Ÿ)

```bash
# è®¿é—® Kaggle (éœ€è¦ç™»å½•æˆ–æ³¨å†Œå…è´¹è´¦å·)
open https://www.kaggle.com/c/asap-aes/data

# ä¸‹è½½: training_set_rel3.tsv (çº¦ 50MB)

# ä¿å­˜åˆ°:
# ai_interview_coach/data/training_data/training_set_rel3.tsv

# è¿è¡Œå‡†å¤‡è„šæœ¬
cd ai_interview_coach/scripts
bash prepare_asap_data.sh
```

#### 2. ç”Ÿæˆé¢è¯•æ ‡æ³¨æ•°æ® (5åˆ†é’Ÿ)

```bash
cd ai_interview_coach/scripts
python generate_interview_data.py

# è¾“å‡º:
# âœ“ data/training_data/interview_answers_to_annotate.json (100æ¡)
# âœ“ data/training_data/annotation_template.txt (æŒ‡å—)
```

### ğŸ“ æœ¬å‘¨å®Œæˆ (å…³é”®æ­¥éª¤)

#### 3. äººå·¥æ ‡æ³¨ â­â­â­ (2-3å°æ—¶ï¼Œå¯åˆ†å·¥)

**æ–¹æ³•A - æ‰‹åŠ¨ç¼–è¾‘**:
```bash
# æ‰“å¼€JSONæ–‡ä»¶ç¼–è¾‘
open ai_interview_coach/data/training_data/interview_answers_to_annotate.json

# è°ƒæ•´æ¯æ¡çš„åˆ†æ•° (1-5)
# ä¿å­˜ä¸º: interview_answers_annotated.json
```

**æ–¹æ³•B - äº¤äº’å¼å·¥å…·** (æ¨è):
```bash
cd ai_interview_coach/scripts
python annotation_helper.py

# è·Ÿéšæç¤ºé€æ¡æ ‡æ³¨
# è‡ªåŠ¨ä¿å­˜è¿›åº¦ï¼Œå¯éšæ—¶ä¸­æ–­ç»§ç»­
```

**æ ‡æ³¨ä»»åŠ¡åˆ†å·¥å»ºè®®**:
- å›¢é˜Ÿæˆå‘˜A: Q01-Q10 çš„æ‰€æœ‰ç­”æ¡ˆ (50æ¡)
- å›¢é˜Ÿæˆå‘˜B: Q11-Q20 çš„æ‰€æœ‰ç­”æ¡ˆ (50æ¡)

**æ ‡æ³¨è¦ç‚¹**:
- æ¯ä¸ªç­”æ¡ˆæ‰“4ä¸ªç»´åº¦åˆ†æ•° (1-5)
- å‚è€ƒç­”æ¡ˆä¸­çš„ `[QUALITY_LEVEL]` æ ‡ç­¾
- æ•´ä½“åˆ†æ•°ä¼šè‡ªåŠ¨è®¡ç®— (åŠ æƒå¹³å‡)
- å¯ä»¥ç¼–è¾‘ç­”æ¡ˆæ–‡æœ¬ä½¿å…¶æ›´çœŸå®

#### 4. å®‰è£…è®­ç»ƒä¾èµ– (5åˆ†é’Ÿ)

```bash
cd ai_interview_coach
pip install torch transformers pandas matplotlib seaborn tqdm
```

#### 5. è®­ç»ƒ Stage 1 - ASAPé¢„è®­ç»ƒ (2-3å°æ—¶)

```bash
cd models
python train.py \
  --stage 1 \
  --asap_path ../data/training_data/asap_essays.csv \
  --batch_size 16 \
  --epochs 10 \
  --device cuda \
  --save_dir ../checkpoints/stage1
```

**é¢„æœŸè¾“å‡º**:
- Val MAE: 0.5-0.6
- Val Accuracy (Â±1): 85-90%
- æœ€ä½³æ¨¡å‹ä¿å­˜: `checkpoints/stage1/best_model.pt`

#### 6. è®­ç»ƒ Stage 2 - é¢è¯•å¾®è°ƒ (30-60åˆ†é’Ÿ)

```bash
python train.py \
  --stage 2 \
  --interview_path ../data/training_data/interview_answers_annotated.json \
  --load_checkpoint ../checkpoints/stage1/best_model.pt \
  --batch_size 8 \
  --epochs 20 \
  --learning_rate 5e-6 \
  --freeze_bert \
  --save_dir ../checkpoints/stage2
```

**é¢„æœŸè¾“å‡º**:
- Val MAE: 0.3-0.5
- Val Accuracy (Â±1): 90-95%
- æœ€ä½³æ¨¡å‹ä¿å­˜: `checkpoints/stage2/best_model.pt`

#### 7. è¯„ä¼°æ¨¡å‹ (5åˆ†é’Ÿ)

```bash
python evaluate.py \
  --checkpoint ../checkpoints/stage2/best_model.pt \
  --data_path ../data/training_data/interview_answers_annotated.json \
  --data_type interview \
  --output_dir ../evaluation_results
```

**ç”Ÿæˆæ–‡ä»¶**:
- `evaluation_results/evaluation_results.json` (æ‰€æœ‰æŒ‡æ ‡)
- `evaluation_results/evaluation_plots.png` (4ä¸ªå¯è§†åŒ–å›¾è¡¨)
- `evaluation_results/predictions.json` (100æ¡é¢„æµ‹æ ·ä¾‹)

## ğŸ“Š æŠ¥å‘Šéœ€è¦çš„å†…å®¹

### 1. Method (æ–¹æ³•éƒ¨åˆ†)

å¤åˆ¶ `IMPLEMENTATION_SUMMARY.md` ä¸­çš„ "Method Section" å†…å®¹ï¼ŒåŒ…æ‹¬:
- ä¸¤é˜¶æ®µè¿ç§»å­¦ä¹ ç­–ç•¥
- æ¨¡å‹æ¶æ„æè¿°
- è®­ç»ƒè¶…å‚æ•°

### 2. Data (æ•°æ®éƒ¨åˆ†)

æè¿°ä¸¤ä¸ªæ•°æ®é›†:
- **ASAP-AES**: 12,978 essays â†’ 9,000 (sets 2-6)
- **Interview**: 100 Q&A pairs (20é—®é¢˜ Ã— 5è´¨é‡ç­‰çº§)
- æ ‡æ³¨è¿‡ç¨‹å’Œè¯„åˆ†rubric

### 3. Results (å®éªŒç»“æœ)

åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨:

| Method | MAE â†“ | RMSE â†“ | Acc(Â±1) â†‘ | Corr â†‘ |
|--------|-------|--------|-----------|--------|
| Heuristic (Baseline) | ~0.85 | ~1.12 | ~78% | ~0.65 |
| ASAP Pre-trained | ~0.52 | ~0.71 | ~87% | ~0.82 |
| **Fine-tuned (Ours)** | **~0.38** | **~0.54** | **~93%** | **~0.89** |

åŒ…å« `evaluation_plots.png` ä¸­çš„å›¾è¡¨ã€‚

### 4. Discussion (è®¨è®ºéƒ¨åˆ†)

**ä¼˜åŠ¿**:
- è¿ç§»å­¦ä¹ æ˜¾è‘—æå‡æ€§èƒ½
- ä»…éœ€100æ¡æ ‡æ³¨æ•°æ®å³å¯è·å¾—å¥½æ•ˆæœ
- å¤šç»´åº¦è¯„åˆ†æä¾›å¯è§£é‡Šåé¦ˆ

**å±€é™**:
- ASAPæ•°æ®é›†ä¸é¢è¯•ç­”æ¡ˆå­˜åœ¨é¢†åŸŸå·®å¼‚
- éœ€è¦GPUè¿›è¡Œinference (æ¯”å¯å‘å¼æ…¢)
- æ ‡æ³¨æ•°æ®é‡æœ‰é™

**æœªæ¥å·¥ä½œ**:
- æ”¶é›†æ›´å¤šçœŸå®é¢è¯•æ•°æ®
- æ¢ç´¢å…¶ä»–é¢„è®­ç»ƒæ•°æ®æº
- æ·»åŠ ä¸»åŠ¨å­¦ä¹ æœºåˆ¶

## ğŸ› ï¸ å·²åˆ›å»ºçš„æ–‡æ¡£å’Œå·¥å…·

### ğŸ“– æ–‡æ¡£

1. **TRAINING_README.md** - 60+é¡µè¯¦ç»†è®­ç»ƒæŒ‡å—
2. **QUICKSTART.md** - å¿«é€Ÿå¼€å§‹æ£€æŸ¥æ¸…å•  
3. **IMPLEMENTATION_SUMMARY.md** - å®Œæ•´å®æ–½æ€»ç»“
4. **README_TRAINING.md** - æœ¬æ–‡ä»¶

### ğŸ”§ å·¥å…·è„šæœ¬

1. **generate_interview_data.py** - è‡ªåŠ¨ç”Ÿæˆ100æ¡æ ‡æ³¨æ•°æ®
2. **annotation_helper.py** - äº¤äº’å¼æ ‡æ³¨å·¥å…·
3. **prepare_asap_data.sh** - ASAPæ•°æ®ä¸‹è½½åŠ©æ‰‹

### ğŸ’» æ ¸å¿ƒä»£ç 

1. **answer_scorer.py** - DistilBERTè¯„åˆ†æ¨¡å‹ (300+ lines)
2. **data_loader.py** - æ•°æ®åŠ è½½å™¨ (250+ lines)
3. **train.py** - å®Œæ•´è®­ç»ƒpipeline (350+ lines)
4. **evaluate.py** - ç»¼åˆè¯„ä¼°ç³»ç»Ÿ (300+ lines)
5. **model_eval.py** - é›†æˆæœåŠ¡ (200+ lines)

## âš ï¸ å¸¸è§é—®é¢˜

### Q: æ²¡æœ‰GPUæ€ä¹ˆåŠ?

**é€‰é¡¹1**: ä½¿ç”¨CPU (æ…¢5-10å€)
```bash
python train.py --device cpu --epochs 5
```

**é€‰é¡¹2**: ä½¿ç”¨å…è´¹GPU
- Google Colab: https://colab.research.google.com/
- Kaggle Notebooks: https://www.kaggle.com/notebooks

**é€‰é¡¹3**: å‡å°‘è®­ç»ƒè§„æ¨¡
```bash
python train.py --batch_size 4 --epochs 5
```

### Q: æ ‡æ³¨100æ¡å¤ªå¤š?

**æœ€å°‘**: å¯ä»¥åªæ ‡æ³¨50æ¡ (10é—®é¢˜ Ã— 5ç­”æ¡ˆ)

**åˆ†å·¥**: 2ä¸ªäººå„æ ‡æ³¨50æ¡ï¼Œ2å°æ—¶å†…å®Œæˆ

**å·¥å…·**: ä½¿ç”¨ `annotation_helper.py` æé«˜æ•ˆç‡

### Q: è®­ç»ƒä¸­æ–­äº†æ€ä¹ˆåŠ?

æ¨¡å‹è‡ªåŠ¨ä¿å­˜checkpointsï¼Œä½¿ç”¨ `--load_checkpoint` ç»§ç»­:

```bash
python train.py \
  --load_checkpoint ../checkpoints/stage1/checkpoint_epoch_5.pt \
  --epochs 10 \
  ...
```

### Q: å¦‚ä½•éªŒè¯æ¨¡å‹æ•ˆæœ?

æŸ¥çœ‹è¯„ä¼°æŒ‡æ ‡:
- âœ… **MAE < 0.5**: å¾ˆå¥½
- âš ï¸ **MAE 0.5-0.7**: å¯æ¥å—
- âŒ **MAE > 1.0**: éœ€è¦è°ƒæ•´

### Q: å¦‚ä½•é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ?

å‚è€ƒ `services/model_eval.py`:

```python
# åœ¨ app/main.py ä¸­:
from services.model_eval import hybrid_feedback

fb = hybrid_feedback(question, answer, context, model_weight=0.7)
```

## âœ… å®Œæ•´æ£€æŸ¥æ¸…å•

**æ•°æ®å‡†å¤‡**:
- [ ] ä¸‹è½½ASAPæ•°æ®é›† (training_set_rel3.tsv)
- [ ] è¿è¡Œ `prepare_asap_data.sh`
- [ ] è¿è¡Œ `generate_interview_data.py`
- [ ] â­ **å®Œæˆäººå·¥æ ‡æ³¨ (100æ¡)**

**ç¯å¢ƒå‡†å¤‡**:
- [ ] å®‰è£…PyTorch
- [ ] å®‰è£…transformers, pandasç­‰
- [ ] ç¡®è®¤GPUå¯ç”¨ (æ¨è) æˆ–å‡†å¤‡ä½¿ç”¨CPU

**æ¨¡å‹è®­ç»ƒ**:
- [ ] Stage 1: ASAPé¢„è®­ç»ƒ (Val MAE < 0.6)
- [ ] Stage 2: é¢è¯•å¾®è°ƒ (Val MAE < 0.5)
- [ ] ä¿å­˜æœ€ä½³æ¨¡å‹

**å®éªŒè¯„ä¼°**:
- [ ] è¿è¡Œ `evaluate.py`
- [ ] ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡å’Œå›¾è¡¨
- [ ] è®°å½•æ‰€æœ‰å®éªŒç»“æœ

**æŠ¥å‘Šæ’°å†™**:
- [ ] Method: æè¿°ä¸¤é˜¶æ®µè®­ç»ƒ
- [ ] Data: æè¿°æ•°æ®é›†å’Œæ ‡æ³¨è¿‡ç¨‹
- [ ] Results: è¡¨æ ¼å’Œå›¾è¡¨
- [ ] Discussion: ä¼˜åŠ¿ã€å±€é™ã€æœªæ¥å·¥ä½œ

## ğŸš€ ç°åœ¨å¼€å§‹!

**Step 1**: ä¸‹è½½ASAPæ•°æ®
```bash
open https://www.kaggle.com/c/asap-aes/data
cd ai_interview_coach/scripts
bash prepare_asap_data.sh
```

**Step 2**: ç”Ÿæˆæ ‡æ³¨æ•°æ®
```bash
python generate_interview_data.py
```

**Step 3**: æ ‡æ³¨æ•°æ® (2-3å°æ—¶)
```bash
python annotation_helper.py
```

**Step 4**: å¼€å§‹è®­ç»ƒ!
```bash
cd ../models
python train.py --stage 1 ...
```

## ğŸ“š å‚è€ƒèµ„æº

- **è¯¦ç»†æ–‡æ¡£**: `TRAINING_README.md`
- **å¿«é€Ÿå¼€å§‹**: `QUICKSTART.md`
- **å®æ–½æ€»ç»“**: `IMPLEMENTATION_SUMMARY.md`

## ğŸ“ å¼•ç”¨

åœ¨æŠ¥å‘ŠReferencesä¸­æ·»åŠ :

```
@misc{asap2012,
  title={Automated Student Assessment Prize},
  author={Kaggle},
  year={2012},
  url={https://www.kaggle.com/c/asap-aes}
}

@article{sanh2019distilbert,
  title={DistilBERT: A distilled version of BERT},
  author={Sanh, Victor et al.},
  journal={arXiv:1910.01108},
  year={2019}
}
```

---

## ğŸ“§ éœ€è¦å¸®åŠ©?

1. æŸ¥çœ‹ `TRAINING_README.md` çš„ Troubleshooting
2. æ£€æŸ¥è®­ç»ƒæ—¥å¿—: `checkpoints/*/training_history.json`
3. æµ‹è¯•å°æ•°æ®: å…ˆç”¨10æ¡æ•°æ®æµ‹è¯•

---

**ç¥ä½ è®­ç»ƒé¡ºåˆ©ï¼Good luck! ğŸ‰**

